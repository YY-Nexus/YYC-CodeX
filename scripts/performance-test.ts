#!/usr/bin/env tsx

import { performance } from "perf_hooks"
import autocannon from "autocannon"
import { writeFileSync } from "fs"
import { join } from "path"

interface PerformanceMetrics {
  timestamp: string
  testType: string
  duration: number
  requests: {
    total: number
    average: number
    min: number
    max: number
  }
  latency: {
    average: number
    min: number
    max: number
    p50: number
    p90: number
    p95: number
    p99: number
  }
  throughput: {
    average: number
    min: number
    max: number
  }
  errors: number
  timeouts: number
}

class PerformanceTester {
  private baseUrl: string
  private results: PerformanceMetrics[] = []

  constructor(baseUrl = "http://localhost:3000") {
    this.baseUrl = baseUrl
  }

  async runLoadTest(
    endpoint: string,
    options: {
      connections?: number
      duration?: number
      pipelining?: number
      title?: string
    } = {},
  ): Promise<PerformanceMetrics> {
    const { connections = 10, duration = 30, pipelining = 1, title = endpoint } = options

    console.log(`ğŸš€ å¼€å§‹è´Ÿè½½æµ‹è¯•: ${title}`)
    console.log(`ğŸ“Š é…ç½®: ${connections} è¿æ¥, ${duration}s æŒç»­æ—¶é—´, ${pipelining} ç®¡é“`)

    const startTime = performance.now()

    try {
      const result = await autocannon({
        url: `${this.baseUrl}${endpoint}`,
        connections,
        duration,
        pipelining,
        headers: {
          "User-Agent": "YYC3-Performance-Test/1.0",
        },
      })

      const endTime = performance.now()
      const testDuration = endTime - startTime

      const metrics: PerformanceMetrics = {
        timestamp: new Date().toISOString(),
        testType: title,
        duration: testDuration,
        requests: {
          total: result.requests.total,
          average: result.requests.average,
          min: result.requests.min,
          max: result.requests.max,
        },
        latency: {
          average: result.latency.average,
          min: result.latency.min,
          max: result.latency.max,
          p50: result.latency.p50,
          p90: result.latency.p90,
          p95: result.latency.p95,
          p99: result.latency.p99,
        },
        throughput: {
          average: result.throughput.average,
          min: result.throughput.min,
          max: result.throughput.max,
        },
        errors: result.errors,
        timeouts: result.timeouts,
      }

      this.results.push(metrics)
      this.logResults(metrics)

      return metrics
    } catch (error) {
      console.error(`âŒ è´Ÿè½½æµ‹è¯•å¤±è´¥: ${error}`)
      throw error
    }
  }

  private logResults(metrics: PerformanceMetrics) {
    console.log(`\nğŸ“ˆ ${metrics.testType} æµ‹è¯•ç»“æœ:`)
    console.log(`   æ€»è¯·æ±‚æ•°: ${metrics.requests.total}`)
    console.log(`   å¹³å‡ RPS: ${metrics.requests.average}`)
    console.log(`   å¹³å‡å»¶è¿Ÿ: ${metrics.latency.average}ms`)
    console.log(`   P95 å»¶è¿Ÿ: ${metrics.latency.p95}ms`)
    console.log(`   P99 å»¶è¿Ÿ: ${metrics.latency.p99}ms`)
    console.log(`   é”™è¯¯æ•°: ${metrics.errors}`)
    console.log(`   è¶…æ—¶æ•°: ${metrics.timeouts}`)
    console.log(`   å¹³å‡ååé‡: ${metrics.throughput.average} bytes/sec`)
  }

  async runFullTestSuite(): Promise<void> {
    console.log("ğŸ¯ å¼€å§‹å®Œæ•´æ€§èƒ½æµ‹è¯•å¥—ä»¶...\n")

    const testCases = [
      { endpoint: "/", title: "é¦–é¡µåŠ è½½æµ‹è¯•", connections: 10, duration: 30 },
      { endpoint: "/api/health", title: "API å¥åº·æ£€æŸ¥", connections: 20, duration: 30 },
      { endpoint: "/api/network/test", title: "ç½‘ç»œæµ‹è¯• API", connections: 5, duration: 30 },
      { endpoint: "/api/feedback", title: "åé¦ˆ API", connections: 10, duration: 20 },
      { endpoint: "/docs", title: "API æ–‡æ¡£é¡µé¢", connections: 5, duration: 20 },
    ]

    for (const testCase of testCases) {
      try {
        await this.runLoadTest(testCase.endpoint, testCase)
        console.log("\n" + "â”€".repeat(60) + "\n")

        // æµ‹è¯•é—´éš”
        await new Promise((resolve) => setTimeout(resolve, 5000))
      } catch (error) {
        console.error(`æµ‹è¯•å¤±è´¥: ${testCase.title}`, error)
      }
    }

    this.generateReport()
  }

  private generateReport(): void {
    const reportPath = join(process.cwd(), "performance-report.json")
    const htmlReportPath = join(process.cwd(), "performance-report.html")

    // ç”Ÿæˆ JSON æŠ¥å‘Š
    const report = {
      timestamp: new Date().toISOString(),
      summary: this.generateSummary(),
      results: this.results,
    }

    writeFileSync(reportPath, JSON.stringify(report, null, 2))
    console.log(`ğŸ“„ JSON æŠ¥å‘Šå·²ç”Ÿæˆ: ${reportPath}`)

    // ç”Ÿæˆ HTML æŠ¥å‘Š
    const htmlReport = this.generateHtmlReport(report)
    writeFileSync(htmlReportPath, htmlReport)
    console.log(`ğŸ“„ HTML æŠ¥å‘Šå·²ç”Ÿæˆ: ${htmlReportPath}`)
  }

  private generateSummary() {
    if (this.results.length === 0) return null

    const totalRequests = this.results.reduce((sum, r) => sum + r.requests.total, 0)
    const totalErrors = this.results.reduce((sum, r) => sum + r.errors, 0)
    const avgLatency = this.results.reduce((sum, r) => sum + r.latency.average, 0) / this.results.length
    const maxLatency = Math.max(...this.results.map((r) => r.latency.max))

    return {
      totalTests: this.results.length,
      totalRequests,
      totalErrors,
      errorRate: (totalErrors / totalRequests) * 100,
      averageLatency: avgLatency,
      maxLatency,
      overallScore: this.calculateOverallScore(),
    }
  }

  private calculateOverallScore(): string {
    const summary = this.generateSummary()
    if (!summary) return "N/A"

    let score = 100

    // é”™è¯¯ç‡æ‰£åˆ†
    if (summary.errorRate > 1) score -= 30
    else if (summary.errorRate > 0.1) score -= 10

    // å»¶è¿Ÿæ‰£åˆ†
    if (summary.averageLatency > 1000) score -= 30
    else if (summary.averageLatency > 500) score -= 20
    else if (summary.averageLatency > 200) score -= 10

    if (score >= 90) return "ä¼˜ç§€"
    if (score >= 80) return "è‰¯å¥½"
    if (score >= 70) return "ä¸€èˆ¬"
    return "éœ€è¦ä¼˜åŒ–"
  }

  private generateHtmlReport(report: any): string {
    return `
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YYCÂ³ NetTrack æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; background: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 8px 8px 0 0; }
        .content { padding: 30px; }
        .summary { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }
        .metric { background: #f8f9fa; padding: 20px; border-radius: 8px; text-align: center; }
        .metric-value { font-size: 2em; font-weight: bold; color: #333; }
        .metric-label { color: #666; margin-top: 5px; }
        .test-result { margin-bottom: 30px; border: 1px solid #e9ecef; border-radius: 8px; overflow: hidden; }
        .test-header { background: #f8f9fa; padding: 15px; font-weight: bold; }
        .test-details { padding: 15px; display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 15px; }
        .detail-item { text-align: center; }
        .detail-value { font-size: 1.2em; font-weight: bold; }
        .detail-label { color: #666; font-size: 0.9em; }
        .score-excellent { color: #28a745; }
        .score-good { color: #17a2b8; }
        .score-average { color: #ffc107; }
        .score-poor { color: #dc3545; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ YYCÂ³ NetTrack æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</h1>
            <p>ç”Ÿæˆæ—¶é—´: ${report.timestamp}</p>
        </div>
        <div class="content">
            ${
              report.summary
                ? `
            <div class="summary">
                <div class="metric">
                    <div class="metric-value">${report.summary.totalTests}</div>
                    <div class="metric-label">æµ‹è¯•ç”¨ä¾‹</div>
                </div>
                <div class="metric">
                    <div class="metric-value">${report.summary.totalRequests.toLocaleString()}</div>
                    <div class="metric-label">æ€»è¯·æ±‚æ•°</div>
                </div>
                <div class="metric">
                    <div class="metric-value">${report.summary.errorRate.toFixed(2)}%</div>
                    <div class="metric-label">é”™è¯¯ç‡</div>
                </div>
                <div class="metric">
                    <div class="metric-value">${report.summary.averageLatency.toFixed(0)}ms</div>
                    <div class="metric-label">å¹³å‡å»¶è¿Ÿ</div>
                </div>
                <div class="metric">
                    <div class="metric-value score-${report.summary.overallScore === "ä¼˜ç§€" ? "excellent" : report.summary.overallScore === "è‰¯å¥½" ? "good" : report.summary.overallScore === "ä¸€èˆ¬" ? "average" : "poor"}">${report.summary.overallScore}</div>
                    <div class="metric-label">ç»¼åˆè¯„åˆ†</div>
                </div>
            </div>
            `
                : ""
            }
            
            <h2>ğŸ“Š è¯¦ç»†æµ‹è¯•ç»“æœ</h2>
            ${report.results
              .map(
                (result: PerformanceMetrics) => `
            <div class="test-result">
                <div class="test-header">${result.testType}</div>
                <div class="test-details">
                    <div class="detail-item">
                        <div class="detail-value">${result.requests.total}</div>
                        <div class="detail-label">æ€»è¯·æ±‚æ•°</div>
                    </div>
                    <div class="detail-item">
                        <div class="detail-value">${result.requests.average}</div>
                        <div class="detail-label">å¹³å‡ RPS</div>
                    </div>
                    <div class="detail-item">
                        <div class="detail-value">${result.latency.average.toFixed(1)}ms</div>
                        <div class="detail-label">å¹³å‡å»¶è¿Ÿ</div>
                    </div>
                    <div class="detail-item">
                        <div class="detail-value">${result.latency.p95.toFixed(1)}ms</div>
                        <div class="detail-label">P95 å»¶è¿Ÿ</div>
                    </div>
                    <div class="detail-item">
                        <div class="detail-value">${result.latency.p99.toFixed(1)}ms</div>
                        <div class="detail-label">P99 å»¶è¿Ÿ</div>
                    </div>
                    <div class="detail-item">
                        <div class="detail-value">${result.errors}</div>
                        <div class="detail-label">é”™è¯¯æ•°</div>
                    </div>
                </div>
            </div>
            `,
              )
              .join("")}
        </div>
    </div>
</body>
</html>
    `
  }
}

// ä¸»å‡½æ•°
async function main() {
  const baseUrl = process.env.TEST_URL || "http://localhost:3000"
  const tester = new PerformanceTester(baseUrl)

  try {
    await tester.runFullTestSuite()
    console.log("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ!")
  } catch (error) {
    console.error("âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥:", error)
    process.exit(1)
  }
}

if (require.main === module) {
  main()
}

export { PerformanceTester, type PerformanceMetrics }
